{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This code calculates the inputs parameter by assimilating to flux tower data in West Phoenix. The results are discussed in section 3.3 of the paper. \n",
    "\n",
    "## Instructions\n",
    "\n",
    "This file should be run in Google Colab.\n",
    "\n",
    "A total of 50 trials are run. Each optimisation trial uses a different set of initial parameter values. One active session in Google Colab uses 2 CPUs, allowing a maximum of 10 trials to be run simultaneously with 5 active sessions. \n",
    "\n",
    "**To run the file:**\n",
    "1. Upload and open the file in Google Colab.\n",
    "2. Click **Files** in Google Colab and upload *US-WestPhoenix_era5_corrected_v1.nc* and *591_fluxtower_data_a16dafefa6836b419580f353b76bc2a0.csv* into the file storage.\n",
    "3. Run the code.\n",
    "4. To open another active session, save a copy of this file and open it in another tab. Adjust the trial numbers at the bottom of the code to generate the next 10 sets of initial parameter values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jz6Gi9ad2xvK"
   },
   "outputs": [],
   "source": [
    "#-- Import general libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xarray as xr\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random_no = torch.rand(50, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dHtwj-nhHK4P"
   },
   "outputs": [],
   "source": [
    "# Observations\n",
    "# Time in UTC\n",
    "\n",
    "start = 0 #time to start optimisation\n",
    "Nt = 150 #total time for optimisation\n",
    "\n",
    "no_periods = start+Nt+1\n",
    "daterange_UTC = pd.date_range(\"2012-05-01 07:00:00\", freq=\"1h\", periods=no_periods) #local standard time = -7 UTC\n",
    "daterange_local = pd.date_range(\"2012-05-01 00:00:00\", freq=\"1h\", periods=no_periods)\n",
    "ds_era5_corrected = xr.open_dataset('US-WestPhoenix_era5_corrected_v1.nc')\n",
    "data_corrected = ds_era5_corrected.sel(time=daterange_UTC)\n",
    "df = pd.read_csv('591_fluxtower_data_a16dafefa6836b419580f353b76bc2a0.csv')\n",
    "df2 = df.loc[df[\"TIMESTAMP\"].between(str(daterange_local[0]), str(daterange_local[-1]))]\n",
    "\n",
    "# Thermal & radiation properties\n",
    "epsilon = 0.95\n",
    "sigma = 5.67e-8\n",
    "mid_day_alpha = 0.172\n",
    "\n",
    "# Forcing data\n",
    "K_down_array = data_corrected['SWdown']\n",
    "L_down_array = data_corrected['LWdown']\n",
    "Ta_array = data_corrected['Tair']\n",
    "\n",
    "# Target temperatures & air temperature\n",
    "target_T2 = np.array(df2['Temp_C_Avg'][0::2]+273.15)[start:]\n",
    "target_T5 = np.array(df2['Temp_C_2_Avg'][0::2]+273.15)[start:]\n",
    "target_T15 = np.array(df2['Temp_C_3_Avg'][0::2]+273.15)[start:]\n",
    "\n",
    "# Convert to tensors\n",
    "K_down_array = torch.tensor(np.array(K_down_array),dtype=torch.float64)\n",
    "L_down_array = torch.tensor(np.array(L_down_array),dtype=torch.float64)\n",
    "Ta_array = torch.tensor(np.array(Ta_array),dtype=torch.float64)\n",
    "\n",
    "target_T2 = torch.tensor(np.array(target_T2),dtype=torch.float64)\n",
    "target_T5 = torch.tensor(np.array(target_T5),dtype=torch.float64)\n",
    "target_T15 = torch.tensor(np.array(target_T15),dtype=torch.float64)\n",
    "target = torch.zeros(2,Nt+1, dtype=torch.float64)\n",
    "target[0,:] = target_T5\n",
    "target[1,:] = target_T15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELSYj2cJ4I_f"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "# Define the function to be executed by each process\n",
    "def worker_function(x):\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    # Specify size of the domain\n",
    "    Nx = 101\n",
    "    xa = 0\n",
    "    xb = 1\n",
    "\n",
    "    # Create a meshgrid\n",
    "    x_array = np.linspace(xa, xb, Nx) # np array\n",
    "    dx = (xb-xa)/(Nx-1)\n",
    "    depth_measurement = 0.05\n",
    "    depth_i = int(np.floor(depth_measurement/dx))\n",
    "    depth_measurement = 0.15\n",
    "    depth_i_2 = int(np.floor(depth_measurement/dx))\n",
    "\n",
    "    # Time setup\n",
    "    hour = 3600\n",
    "    dt = hour;\n",
    "\n",
    "\n",
    "    #Min & Max values of parameters\n",
    "    h0 = 5\n",
    "    h1 = 20\n",
    "    beta0 = 0.5\n",
    "    beta1 = 5\n",
    "    C0 = 2e6\n",
    "    C1 = 2.5e6\n",
    "    Tb0 = 290\n",
    "    Tb1 = 303\n",
    "    Lambda0 = 0.47\n",
    "    Lambda1 = 0.8\n",
    "\n",
    "    class HeatEqConv(nn.Module):\n",
    "        def __init__(self, Nx, filter_weight): #filter_weight\n",
    "            super(HeatEqConv, self).__init__()\n",
    "\n",
    "            # Specify the size of the input (batch_size, channels, width)\n",
    "            input_size = (1, 1, Nx)  # Adjust the size based on your requirements\n",
    "            batch_size, in_channels, width = input_size\n",
    "\n",
    "            # Specify the size of the filter/kernel\n",
    "            kernel_size = filter_weight.shape[2]\n",
    "\n",
    "            # Create a Conv1d layer with the specified weight, input size, and padding\n",
    "            self.conv_layer = nn.Conv1d(in_channels, out_channels=1,kernel_size=kernel_size, padding='valid', bias=False)\n",
    "            self.conv_layer.weight.data = filter_weight\n",
    "\n",
    "        def forward(self, previous):\n",
    "\n",
    "            future = self.conv_layer(previous) # previous(1,1,Nx); future(1,1,Nx-2)\n",
    "            return future\n",
    "\n",
    "    # Convert NumPy arrays to PyTorch tensors with float type\n",
    "    x_tensor = torch.tensor(np.array(x_array), dtype=torch.float64)\n",
    "\n",
    "    # filter corresponding to the second order central difference of the second derivative\n",
    "    filter = torch.tensor([1, 0., 1], dtype=torch.float64)\n",
    "\n",
    "    # resize filter for PyTorch\n",
    "    # filter_weight(num_kernels/output channels, kernel_height, kernel_width)\n",
    "    filter_weight = filter.view(1, 1, filter.shape[0])\n",
    "\n",
    "    # Create instance of convolution and use it as a function to apply convolution\n",
    "    mymodel_time_march = HeatEqConv(Nx,filter_weight)\n",
    "\n",
    "\n",
    "    def forward(h_beta,Lambda,C,Tb,mymodel_time_march,Nt,start):\n",
    "\n",
    "        h_beta.retain_grad()\n",
    "        Tb.retain_grad()\n",
    "        Lambda.retain_grad()\n",
    "        C.retain_grad()\n",
    "\n",
    "        T_array = torch.zeros(2,Nt+1,dtype=torch.float64)\n",
    "        #Define initial condition\n",
    "        T_array[0,0] = Tb\n",
    "        T_array[1,0] = Tb\n",
    "        Tn1 = Tb*torch.ones(Nx,dtype=torch.float64)\n",
    "        tol = 1e-4\n",
    "\n",
    "        #Solve for temperature at measurement depth\n",
    "        for t in range(start,Nt+start):\n",
    "            Tn1 = HeatEqSolver(mymodel_time_march,Tn1,tol,K_down_array[t+1],L_down_array[t+1],Ta_array[t+1],h_beta,Lambda,C,Tb)\n",
    "            T_array[0,t-start+1] = Tn1[depth_i]\n",
    "            T_array[1,t-start+1] = Tn1[depth_i_2]\n",
    "\n",
    "        return T_array,Tn1\n",
    "\n",
    "    def HeatEqSolver(mymodel_time_march,Tn,tol,K_down,L_down,Ta,h_beta,Lambda,C,Tb):\n",
    "        error = 9e9\n",
    "        # first guess\n",
    "        Tn1_k = Tn\n",
    "        # recalculate r\n",
    "        r = Lambda/C*dt/(dx**2)\n",
    "        while(error>tol):\n",
    "            # Input kth approximation of Tn+1 into NN -> transform into 3D tensor\n",
    "            Tn1_k_tensor= Tn1_k.view(1, 1, Nx)\n",
    "            # Apply convolution to obtain (k+1)th approximation of Tn+1 for interior nodes\n",
    "            Tn1_k1_tensor = 1/(1+2*r)*(r*mymodel_time_march(Tn1_k_tensor) + Tn[1:-1])\n",
    "            # Calculate new Tn+1 at boundary based on Tn and kth approximation of Tn+1\n",
    "            Tn1_k1_0 = 1/(1+2*r*(1+dx/Lambda*(h_beta+sigma*epsilon*Tn1_k[0]**3)))*(Tn[0]+2*r*(Tn1_k[1]+dx/Lambda*(K_down*(1-mid_day_alpha) + L_down + h_beta*Ta)))\n",
    "            # Append BCs\n",
    "            Tn1_k1_tensor  = torch.cat((Tn1_k1_0, Tn1_k1_tensor[0,0,:], Tb),0)\n",
    "            # Calculate error\n",
    "            error = torch.max(torch.abs(Tn1_k1_tensor-Tn1_k))\n",
    "            # Continue from (k+1)th approximation\n",
    "            Tn1_k = Tn1_k1_tensor\n",
    "\n",
    "\n",
    "        return Tn1_k1_tensor\n",
    "\n",
    "    print(r'Trial no: {} '.format(x))\n",
    "\n",
    "    #Random initialisation of parameters\n",
    "    Tb = torch.tensor([Tb0+(Tb1-Tb0)*random_no[x,4]], dtype=torch.float64,requires_grad=True)\n",
    "    h = h0+(h1-h0)*random_no[x,0]\n",
    "    beta = beta0+(beta1-beta0)*random_no[x,1]\n",
    "    C = torch.tensor([C0+(C1-C0)*random_no[x,2]], dtype=torch.float64,requires_grad=True)\n",
    "    Lambda = torch.tensor([Lambda0+(Lambda1-Lambda0)*random_no[x,3]], dtype=torch.float64,requires_grad=True)\n",
    "    h_beta = torch.tensor([h*(1+1/beta)], dtype=torch.float64,requires_grad=True)\n",
    "\n",
    "    losses = [9e9]\n",
    "\n",
    "    its_max = 150\n",
    "\n",
    "    optimizer = torch.optim.Adam([{'params':[h_beta,Tb]},{'params':[Lambda], 'lr':0.2},{'params':[C], 'lr':1e5}],lr=1)\n",
    "\n",
    "    data_values = np.zeros([2,4])\n",
    "    rel_change_loss = math.inf\n",
    "    delta_pp = [9e9,9e9,9e9,9e9]\n",
    "\n",
    "    n = 0\n",
    "\n",
    "    while max(delta_pp) > 0.1 or rel_change_loss > 0.01:\n",
    "      if n == 0:\n",
    "        data_values[0,:] = [h_beta.item(),Lambda.item(),C.item(),Tb.item()]\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      [output,Tn1] = forward(h_beta,Lambda,C,Tb,mymodel_time_march,Nt,start)\n",
    "      loss = mse_loss(output,target)\n",
    "      hbeta_prev = h_beta.item()\n",
    "      Lambda_prev = Lambda.item()\n",
    "      C_prev = C.item()\n",
    "      Tb_prev = Tb.item()\n",
    "\n",
    "      # Backward pass to calculate gradients\n",
    "      loss.backward(retain_graph=True)\n",
    "\n",
    "      rel_change_loss = abs(losses[-1]-loss.item())/losses[-1]*100\n",
    "\n",
    "      losses.append(loss.item())\n",
    "\n",
    "      # optimize parameters\n",
    "      optimizer.step()\n",
    "\n",
    "      #calculate relative % change in parameters\n",
    "      delta_pp = [abs(hbeta_prev-h_beta.item())/hbeta_prev*100,abs(Lambda_prev-Lambda.item())/Lambda_prev*100,abs(C_prev-C.item())/C_prev*100,abs(Tb_prev-Tb.item())/Tb_prev*100]\n",
    "\n",
    "      if n%5 == 0:\n",
    "        print(r'Trial no.: {}, iterations: {}, loss: {:.5f}, rel change: {:.5f} % \\n'.format(x,n,loss.item(),rel_change_loss))\n",
    "        print(r'Trial no.: {}, h_beta:{:.5f}, Lambda:{:.5f}, C:{:.5f}, Tb:{:.5f} \\n'.format(x,h_beta.item(),Lambda.item(),C.item(),Tb.item()))\n",
    "        print(r'Trial no.: {}, h_beta_delta:{:.5f}%, Lambda_delta:{:.5f}%, C_delta:{:.5f}% \\n'.format(x,delta_pp[0],delta_pp[1],delta_pp[2],delta_pp[3]))\n",
    "        print('\\n')\n",
    "\n",
    "      n = n+1\n",
    "      if n > its_max:\n",
    "        break\n",
    "\n",
    "\n",
    "    data_values[1,:] = [h_beta.item(),Lambda.item(),C.item(),Tb.item()]\n",
    "\n",
    "    return(data_values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor:\n",
    "      inputs = list(range(10)) #first 10 trials\n",
    "      resultsi = executor.map(worker_function, inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chEKUbjt5l__"
   },
   "outputs": [],
   "source": [
    "results_temp = list(resultsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "mV7q6h_DD9Pz",
    "outputId": "6b77796e-639d-46e9-a9c2-6b2495ad1f88"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_08716244-da3e-4fcb-b5ab-f69cfa095dba\", \"final_parameter_values_WP_T5T15_5.txt\", 1110)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('final_parameter_values_WP_1.txt','w') as outfile:\n",
    "  for trial_no in range(10):\n",
    "    outfile.write('#Trial no.{}\\n'.format([trial_no]))\n",
    "    np.savetxt(outfile,results_temp[trial_no],fmt='%-7.5e')\n",
    "\n",
    "from google.colab import files\n",
    "files.download('final_parameter_values_WP_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNVfxnY77ZMT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
