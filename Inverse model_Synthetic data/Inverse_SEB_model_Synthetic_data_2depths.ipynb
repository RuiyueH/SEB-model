{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "This code calculates the input parameters by assimilating to the synthetic data generated using the forward model. Both sets of temperature data (at surface and 5cm) are used.The results are discussed in section 3.2 of the paper.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "This file should be run in Google Colab.\n",
        "\n",
        "A total of 50 trials are run. Each optimisation trial uses a different set of initial parameter values. One active session in Google Colab uses 2 CPUs, allowing a maximum of 10 trials to be run simultaneously with 5 active sessions. \n",
        "\n",
        "**To run the file:**\n",
        "1. Upload and open the file in Google Colab.\n",
        "2. Click **Files** in Google Colab and upload both *Target_T1.txt* and *Target_T2.txt* into the file storage.\n",
        "3. Run the code.\n",
        "4. To open another active session, save a copy of this file and open it in another tab. Adjust the trial numbers at the bottom of the code to generate the next 10 sets of initial parameter values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz6Gi9ad2xvK"
      },
      "outputs": [],
      "source": [
        "#-- Import general libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import sys\n",
        "import scipy\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELSYj2cJ4I_f"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "import concurrent.futures\n",
        "\n",
        "\n",
        "# Define the function to be executed by each process\n",
        "def worker_function(x):\n",
        "    start = 0\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    # Specify size of the domain\n",
        "    Nx = 101\n",
        "    xa = 0\n",
        "    xb = 1\n",
        "\n",
        "    # Create a meshgrid\n",
        "    x_array = np.linspace(xa, xb, Nx) # np array\n",
        "    dx = (xb-xa)/(Nx-1)\n",
        "    depth_measurement = 0.05\n",
        "    depth_i = int(np.floor(depth_measurement/dx))\n",
        "\n",
        "    # Time setup\n",
        "    hour = 3600\n",
        "    dt = hour;\n",
        "    Nt = 100;\n",
        "    t_total = Nt*dt;\n",
        "    time = np.linspace(0, t_total,Nt+1);\n",
        "\n",
        "    #Thermal & radiation properties\n",
        "    Ta = 296\n",
        "    epsilon = 0.95\n",
        "    sigma = 5.67e-8\n",
        "    K_down = 800\n",
        "    L_down = 100\n",
        "\n",
        "    #Min & Max values of parameters\n",
        "    alpha0 = 0.05\n",
        "    alpha1 = 0.5\n",
        "    h0 = 5\n",
        "    h1 = 20\n",
        "    beta0 = 0.5\n",
        "    beta1 = 5\n",
        "    C0 = 2e6\n",
        "    C1 = 2.5e6\n",
        "    Tb0 = 290\n",
        "    Tb1 = 303\n",
        "    Lambda0 = 0.47\n",
        "    Lambda1 = 0.8\n",
        "\n",
        "    #True values\n",
        "    alpha_true = 0.2\n",
        "    Lambda_true = 0.8\n",
        "    Tb_true = 293\n",
        "    C_true = 2.2e6\n",
        "    beta_true = 1.5\n",
        "    h_true = 15\n",
        "\n",
        "    class HeatEqConv(nn.Module):\n",
        "        def __init__(self, Nx, filter_weight): #filter_weight\n",
        "            super(HeatEqConv, self).__init__()\n",
        "\n",
        "            # Specify the size of the input (batch_size, channels, width)\n",
        "            input_size = (1, 1, Nx)  # Adjust the size based on your requirements\n",
        "            batch_size, in_channels, width = input_size\n",
        "\n",
        "            # Specify the size of the filter/kernel\n",
        "            kernel_size = filter_weight.shape[2]\n",
        "\n",
        "            # Create a Conv1d layer with the specified weight, input size, and padding\n",
        "            self.conv_layer = nn.Conv1d(in_channels, out_channels=1,kernel_size=kernel_size, padding='valid', bias=False)\n",
        "            self.conv_layer.weight.data = filter_weight\n",
        "\n",
        "        def forward(self, previous):\n",
        "\n",
        "            future = self.conv_layer(previous) # previous(1,1,Nx); future(1,1,Nx-2)\n",
        "            return future\n",
        "\n",
        "    # Convert NumPy arrays to PyTorch tensors with float type\n",
        "    x_tensor = torch.tensor(np.array(x_array), dtype=torch.float64)\n",
        "\n",
        "    # filter corresponding to the second order central difference of the second derivative\n",
        "    filter = torch.tensor([1, 0., 1], dtype=torch.float64)\n",
        "\n",
        "    # resize filter for PyTorch\n",
        "    # filter_weight(num_kernels/output channels, kernel_height, kernel_width)\n",
        "    filter_weight = filter.view(1, 1, filter.shape[0])\n",
        "\n",
        "    # Create instance of convolution and use it as a function to apply convolution\n",
        "    mymodel_time_march = HeatEqConv(Nx,filter_weight)\n",
        "\n",
        "    trise = 7*hour\n",
        "    tset = 21*hour\n",
        "\n",
        "    t24 = np.mod(time, 24*hour);\n",
        "    theta=(t24-trise)/(tset-trise)*np.pi/2 + (t24-tset)/(tset-trise)*np.pi/2;\n",
        "    for i in range(Nt+1):\n",
        "        if abs(theta[i]) > np.pi/2:\n",
        "            theta[i] = theta[i]/abs(theta[i])*np.pi/2\n",
        "\n",
        "    K_down_array = K_down*np.cos(theta)\n",
        "    L_down_array = L_down*np.ones(Nt+1)\n",
        "    Ta_array = Ta*np.ones(Nt+1)\n",
        "\n",
        "    #convert target to tensor\n",
        "    time = np.linspace(0, t_total,Nt+1);\n",
        "    target_T5 = np.loadtxt('Target_T2_euler.txt') # Load soil temperature data at depth 5 cm\n",
        "    target_Ts = np.loadtxt('Target_T1_euler.txt') # Load soil temperature data at surface\n",
        "\n",
        "    target_T5 = torch.tensor(target_T5, dtype=torch.float64)\n",
        "    target_Ts = torch.tensor(target_Ts, dtype=torch.float64)\n",
        "    target = torch.zeros(2,101, dtype=torch.float64)\n",
        "    target[0,:] = target_Ts\n",
        "    target[1,:] = target_T5\n",
        "\n",
        "    torch.manual_seed(0)\n",
        "    random_no = torch.rand(50, 6)\n",
        "\n",
        "    def forward(alpha,h,beta,C,Tb,Lambda,mymodel_time_march,Nt,start):\n",
        "\n",
        "        Tb.retain_grad()\n",
        "        h.retain_grad()\n",
        "        alpha.retain_grad()\n",
        "        beta.retain_grad()\n",
        "        C.retain_grad()\n",
        "        Lambda.retain_grad()\n",
        "\n",
        "\n",
        "        T_array = torch.zeros(2,Nt+1,dtype=torch.float64)\n",
        "        #Define initial condition\n",
        "        T_array[:,0] = 293\n",
        "        Tn1 = 293*torch.ones(Nx,dtype=torch.float64)\n",
        "\n",
        "        tol = 1e-4\n",
        "\n",
        "        #Solve for temperature at measurement depth\n",
        "        for t in range(start,Nt+start):\n",
        "            Tn1 = HeatEqSolver(mymodel_time_march,Tn1,tol,K_down_array[t+1],L_down_array[t+1],Ta_array[t+1],alpha,h,beta,C,Tb,Lambda)\n",
        "            T_array[0,t-start+1] = Tn1[0]\n",
        "            T_array[1,t-start+1] = Tn1[depth_i]\n",
        "\n",
        "        return T_array,Tn1\n",
        "\n",
        "    def HeatEqSolver(mymodel_time_march,Tn, tol,K_down,L_down,Ta,alpha,h,beta,C,Tb,Lambda):\n",
        "        error = 9e9\n",
        "        # first guess\n",
        "        Tn1_k = Tn\n",
        "        # recalculate r\n",
        "        r = Lambda/C*dt/(dx**2)\n",
        "        while(error>tol):\n",
        "            # Input kth approximation of Tn+1 into NN -> transform into 3D tensor\n",
        "            Tn1_k_tensor= Tn1_k.view(1, 1, Nx)\n",
        "            # Apply convolution to obtain (k+1)th approximation of Tn+1 for interior nodes\n",
        "            Tn1_k1_tensor = 1/(1+2*r)*(r*mymodel_time_march(Tn1_k_tensor) + Tn[1:-1])\n",
        "            # Calculate new Tn+1 at boundary based on Tn and kth approximation of Tn+1\n",
        "            Tn1_k1_0 = 1/(1+2*r*(1+dx/Lambda*(h*(1+1/beta)+sigma*epsilon*Tn1_k[0]**3)))*(Tn[0]+2*r*(Tn1_k[1]+dx/Lambda*(K_down*(1-alpha) + L_down + h*(1+1/beta)*Ta)))\n",
        "            # Append BCs\n",
        "            Tn1_k1_tensor  = torch.cat((Tn1_k1_0, Tn1_k1_tensor[0,0,:], Tb),0)\n",
        "            # Calculate error\n",
        "            error = torch.max(torch.abs(Tn1_k1_tensor-Tn1_k))\n",
        "            # Continue from (k+1)th approximation\n",
        "            Tn1_k = Tn1_k1_tensor\n",
        "\n",
        "\n",
        "        return Tn1_k1_tensor\n",
        "\n",
        "    print(r'Trial no: {} '.format(x))\n",
        "    #Random initialisation of parameters\n",
        "    alpha = torch.tensor([alpha0+(alpha1-alpha0)*random_no[x,0]], dtype=torch.float64,requires_grad=True)\n",
        "    h = torch.tensor([h0+(h1-h0)*random_no[x,1]], dtype=torch.float64,requires_grad=True)\n",
        "    beta = torch.tensor([beta0+(beta1-beta0)*random_no[x,2]], dtype=torch.float64,requires_grad=True)\n",
        "    C = torch.tensor([C0+(C1-C0)*random_no[x,3]], dtype=torch.float64,requires_grad=True)\n",
        "    Tb = torch.tensor([Tb0+(Tb1-Tb0)*random_no[x,4]], dtype=torch.float64,requires_grad=True)\n",
        "    Lambda = torch.tensor([Lambda0+(Lambda1-Lambda0)*random_no[x,5]], dtype=torch.float64,requires_grad=True)\n",
        "\n",
        "    losses = [9e9]\n",
        "\n",
        "    its_max = 150\n",
        "\n",
        "    optimizer = torch.optim.Adam([{'params':[Tb]},{'params':[beta,h,alpha,Lambda], 'lr':0.1},{'params':[C], 'lr':1e5}],lr=1)\n",
        "\n",
        "    data_values = np.zeros([2,6])\n",
        "    rel_change_loss = math.inf\n",
        "    delta_pp = [9e9,9e9,9e9,9e9,9e9,9e9]\n",
        "\n",
        "    n = 0\n",
        "\n",
        "    # For each time-step, the model computes the temperature profile and populates an empty tensor of length Nt with calculated temperature values. Loss is obtained by taking the MSE between the output and target values. \n",
        "    while max(delta_pp) > 0.1 or rel_change_loss > 0.01:\n",
        "      if n == 0:\n",
        "        data_values[0,:] = [alpha.item(),h.item(),beta.item(),Lambda.item(),Tb.item(),C.item()]\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      [output,Tn1] = forward(alpha,h,beta,C,Tb,Lambda,mymodel_time_march,Nt,start)\n",
        "      loss = mse_loss(output,target)\n",
        "      alpha_prev = alpha.item()\n",
        "      h_prev = h.item()\n",
        "      beta_prev = beta.item()\n",
        "      Lambda_prev = Lambda.item()\n",
        "      Tb_prev = Tb.item()\n",
        "      C_prev = C.item()\n",
        "\n",
        "      # Backward pass to calculate gradients\n",
        "      loss.backward(retain_graph=True)\n",
        "\n",
        "      rel_change_loss = abs(losses[-1]-loss.item())/losses[-1]*100\n",
        "\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      # optimize parameters\n",
        "      optimizer.step()\n",
        "\n",
        "      #calculate relative % change in parameters\n",
        "      delta_pp = [abs(alpha_prev-alpha.item())/alpha_prev*100,abs(h_prev-h.item())/h_prev*100,abs(beta_prev-beta.item())/beta_prev*100, abs(Lambda_prev-Lambda.item())/Lambda_prev*100,abs(Tb_prev-Tb.item())/Tb_prev*100,abs(C_prev-C.item())/C_prev*100]\n",
        "\n",
        "      if n%5 == 0:\n",
        "        print(r'Trial no.: {}, iterations: {}, loss: {:.5f}, rel change: {:.5f} % \\n'.format(x,n,loss.item(),rel_change_loss))\n",
        "        print(r'Trial no.: {}, alpha: {:.5f}, h: {:.5f}, beta:{:.5f}, Lambda:{:.5f}, Tb:{:.5f}, C:{:.5f} \\n'.format(x,alpha.item(),h.item(),beta.item(),Lambda.item(),Tb.item(),C.item()))\n",
        "        print(r'Trial no.: {}, alpha_delta:{:.5f}%, h_delta:{:.5f}%, beta_delta:{:.5f}%, Lambda_delta:{:.5f}%, Tb_delta:{:.5f}%, C_delta:{:.5f}% \\n'.format(x,delta_pp[0],delta_pp[1],delta_pp[2],delta_pp[3],delta_pp[4],delta_pp[5]))\n",
        "        print('\\n')\n",
        "\n",
        "      n = n+1\n",
        "      if n > its_max:\n",
        "        break\n",
        "\n",
        "    data_values[1,:] = [alpha.item(),h.item(),beta.item(),Lambda.item(),Tb.item(),C.item()]\n",
        "\n",
        "    return(data_values)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor:\n",
        "      inputs = list(range(10)) #first 10 trials\n",
        "      resultsi = executor.map(worker_function, inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iSPIfrb5GHP"
      },
      "outputs": [],
      "source": [
        "#Convert results to a list \n",
        "results_temp = list(resultsi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mV7q6h_DD9Pz",
        "outputId": "4d1318c5-81d9-4df1-8dda-e56bdc592fa5"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_2b82d09a-e488-4f12-a047-bb158e5aba5b\", \"final_parameter_values_2depths_euler_4.txt\", 1590)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with open('final_parameter_values_2depths_1.txt','w') as outfile:\n",
        "  for trial_no in range(10):\n",
        "    outfile.write('#Trial no.{}\\n'.format([trial_no]))\n",
        "    np.savetxt(outfile,results_temp[trial_no],fmt='%-7.5e')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('final_parameter_values_2depths_1.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHSSY4eM3PPX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
